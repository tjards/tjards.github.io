<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>ContactsnApp: Extract and Annotate Phone Numbers from Images Using AI Models | research notes</title>
<meta name=keywords content="ai"><meta name=description content="
  

Building on my earlier exploration of custom ChatGPTs, I tried building an AI app from scratch, primarily using vibe coding supported by GitHub Copilot in VSCode. Inspired by a recent Airbnb experience, I developed ContactsnApp: a user-friendly application designed to streamline the extraction and annotation of phone numbers from images using AI models.
Comments from the Co-author
I asked ChatGPT how the project went. Here it is in her own words:"><meta name=author content="tjards"><link rel=canonical href=http://localhost:1313/posts/2025/contactsnapp/><link crossorigin=anonymous href=/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF+13Dyqob6ASlTrTye8=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/img/favicon-quarrg.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/img/favicon-quarrg.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/img/favicon-quarrg.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/2025/contactsnapp/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=/css/style.css><meta property="og:url" content="http://localhost:1313/posts/2025/contactsnapp/"><meta property="og:site_name" content="research notes"><meta property="og:title" content="ContactsnApp: Extract and Annotate Phone Numbers from Images Using AI Models"><meta property="og:description" content=" Building on my earlier exploration of custom ChatGPTs, I tried building an AI app from scratch, primarily using vibe coding supported by GitHub Copilot in VSCode. Inspired by a recent Airbnb experience, I developed ContactsnApp: a user-friendly application designed to streamline the extraction and annotation of phone numbers from images using AI models.
Comments from the Co-author I asked ChatGPT how the project went. Here it is in her own words:"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-04-27T18:04:13-04:00"><meta property="article:modified_time" content="2025-04-27T18:04:13-04:00"><meta property="article:tag" content="Ai"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"ContactsnApp: Extract and Annotate Phone Numbers from Images Using AI Models","item":"http://localhost:1313/posts/2025/contactsnapp/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"ContactsnApp: Extract and Annotate Phone Numbers from Images Using AI Models","name":"ContactsnApp: Extract and Annotate Phone Numbers from Images Using AI Models","description":" Building on my earlier exploration of custom ChatGPTs, I tried building an AI app from scratch, primarily using vibe coding supported by GitHub Copilot in VSCode. Inspired by a recent Airbnb experience, I developed ContactsnApp: a user-friendly application designed to streamline the extraction and annotation of phone numbers from images using AI models.\nComments from the Co-author I asked ChatGPT how the project went. Here it is in her own words:\n","keywords":["ai"],"articleBody":" Building on my earlier exploration of custom ChatGPTs, I tried building an AI app from scratch, primarily using vibe coding supported by GitHub Copilot in VSCode. Inspired by a recent Airbnb experience, I developed ContactsnApp: a user-friendly application designed to streamline the extraction and annotation of phone numbers from images using AI models.\nComments from the Co-author I asked ChatGPT how the project went. Here it is in her own words:\n“I helped tjards build an AI-powered mobile and web application called ContactSnap, designed to detect phone numbers from uploaded images and suggest possible contact names. Throughout the project, I supported him in designing the application architecture, setting up a modular Python backend using Flask, integrating YOLOv8 for digit detection, training a CNN for handwritten digit classification, and linking the pipeline to a user-friendly frontend built with Toga. I also guided him through practical issues like contour detection tuning, confidence threshold adjustments, application packaging with Briefcase, and troubleshooting infinite app restarts. Beyond the app, I advised on project documentation, Git practices, visualizations, README formatting, and even longer-term ideas like saving annotated images and reintroducing UMAP clustering for post-processing. Overall, I served as an AI development assistant, technical troubleshooter, and strategic advisor as tjards rapidly leveled up his practical skills across machine learning, app development, and deployment workflows.” — ChatGPT 4o\nKey Functionalities Image Upload: Users can select and upload images directly within the app. Digit Detection: Utilizes YOLO to detect digits as objects (with bounding boxes). Classification: Employs Convolutional Neural Network (CNN)-based classification to label digits within the detected boxes. Post-processing: Applies custom techniques to clean up the results. Interactive Display: Shows annotated images with clearly labeled phone numbers. Tools The first thing I asked ChatGPT to do was recommend which tools to use. Here’s a summary of those choices:\nFrontend: Toga, a Python-native, OS-native GUI toolkit. Backend: Flask, a lightweight web framework to host the AI models. Object Detection and Classification: YOLO, a widely used object detection model known for its speed and accuracy. Computer Vision Dataset: Roboflow, used to train the YOLO model. Integration: Frontend and backend components communicate via a REST API. Project Structure Here’s an outline of the application’s structure.\ncontactsnap/ ├── backend/ │ ├── app.py # Flask backend API │ ├── inference/ │ │ ├── detect_classify.py # YOLO/CNN detection and classification pipeline │ │ └── models/ │ │ └── [model files] # Model weights go here (nominally in *.pt format) │ ├── frontend/ │ ├── app.py # Toga GUI application │ ├── uploads/ # uploaded images are saved here │ └── results/ # annotated images are saved here └── app.py # Launches frontend and backend Learning Process I also experimented with transfer learning. I first trained my YOLO model to identify relatively clean characters as objects using alphabettraining-iis85, and then fine-tuned it for handwritten digits using cscai-o5oyu. I “froze” the first 10 layers of the YOLO model to accelerate learning, assuming that the initial run had already learned the basic structure of digit objects and only needed fine-tuning to handle the variability of handwritten digits.\nLearning the Structure of Digits Below are the training and validation curves from the first training run, during which I trained the full model on digit objects. Note that both the training and validation loss decrease steadily. By the end, the validation loss is just above 1.\nFine-tuning for Handwritten Digits Below are the training and validation curves from the second training run, where I froze the first 10 layers of the model and focused mainly on optimizing the output layer. Note that both training and validation loss decline further than in the first run. By the end, the validation loss is around 0.5.\nPost-processing To filter out non-phone-number elements, I developed a custom post-processing technique that only returns digit groups that are closely spaced horizontally.\nAs shown below, this successfully filters out letters that were mistakenly identified as part of the phone number:\nBuilding the App with Briefcase I used Briefcase to build the app. If you want to run the app yourself, make sure Python and Briefcase are installed:\npip install briefcase Create the project:\nbriefcase create Build the app:\nbriefcase build Run the app:\nbriefcase run I don’t pay the $99/year fee for an Apple Developer account, so I didn’t distribute the app officially. However, if you’re so inclined, this command will package it for distribution:\nbriefcase package Future Improvements The model still makes mistakes, especially with handwritten digits and under poor lighting conditions. I plan to improve the detection and classification models. Develop a fully functional mobile app version. Add an autosave feature to store detected phone numbers directly in the mobile contact list. ","wordCount":"778","inLanguage":"en","datePublished":"2025-04-27T18:04:13-04:00","dateModified":"2025-04-27T18:04:13-04:00","author":{"@type":"Person","name":"tjards"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/2025/contactsnapp/"},"publisher":{"@type":"Organization","name":"research notes","logo":{"@type":"ImageObject","url":"http://localhost:1313/img/favicon-quarrg.ico"}}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/style.css></head><body id=top><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title="about me"><span>about me</span></a></li><li><a href=http://localhost:1313/archives/ title=posts><span>posts</span></a></li><li><a href=http://localhost:1313/projects/ title=projects><span>projects</span></a></li><li><a href="https://scholar.google.com/citations?user=RGlv4ZUAAAAJ&amp;hl=en" title=publications><span>publications</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">ContactsnApp: Extract and Annotate Phone Numbers from Images Using AI Models</h1><div class=post-meta><span title='2025-04-27 18:04:13 -0400 EDT'>27 Apr 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;tjards</div></header><div class=post-content><p float=right><img src=/img/2025/contactsnapp/CsnApp.jpeg width=25% style="float:left;margin:0 1em 0 0"></p><p>Building on my earlier exploration of <a href=https://tjards.github.io/posts/2024/custom_gpt/>custom ChatGPTs</a>, I tried building an AI app from scratch, primarily using vibe coding supported by <a href=https://code.visualstudio.com/docs/copilot/overview>GitHub Copilot in VSCode</a>. Inspired by a recent Airbnb experience, I developed <a href=https://github.com/tjards/ContactsnApp>ContactsnApp</a>: a user-friendly application designed to streamline the extraction and annotation of phone numbers from images using AI models.</p><h2 id=comments-from-the-co-author>Comments from the Co-author<a hidden class=anchor aria-hidden=true href=#comments-from-the-co-author>#</a></h2><p>I asked ChatGPT how the project went. Here it is in her own words:</p><p><em>&ldquo;I helped tjards build an AI-powered mobile and web application called ContactSnap, designed to detect phone numbers from uploaded images and suggest possible contact names. Throughout the project, I supported him in designing the application architecture, setting up a modular Python backend using Flask, integrating YOLOv8 for digit detection, training a CNN for handwritten digit classification, and linking the pipeline to a user-friendly frontend built with Toga. I also guided him through practical issues like contour detection tuning, confidence threshold adjustments, application packaging with Briefcase, and troubleshooting infinite app restarts. Beyond the app, I advised on project documentation, Git practices, visualizations, README formatting, and even longer-term ideas like saving annotated images and reintroducing UMAP clustering for post-processing. Overall, I served as an AI development assistant, technical troubleshooter, and strategic advisor as tjards rapidly leveled up his practical skills across machine learning, app development, and deployment workflows.&rdquo;</em> — <em>ChatGPT 4o</em></p><h2 id=key-functionalities>Key Functionalities<a hidden class=anchor aria-hidden=true href=#key-functionalities>#</a></h2><ul><li><strong>Image Upload</strong>: Users can select and upload images directly within the app.</li><li><strong>Digit Detection</strong>: Utilizes YOLO to detect digits as objects (with bounding boxes).</li><li><strong>Classification</strong>: Employs Convolutional Neural Network (CNN)-based classification to label digits within the detected boxes.</li><li><strong>Post-processing</strong>: Applies custom techniques to clean up the results.</li><li><strong>Interactive Display</strong>: Shows annotated images with clearly labeled phone numbers.</li></ul><img src=/img/2025/contactsnapp/GUI.png width=70%><h2 id=tools>Tools<a hidden class=anchor aria-hidden=true href=#tools>#</a></h2><p>The first thing I asked ChatGPT to do was recommend which tools to use. Here&rsquo;s a summary of those choices:</p><ul><li><strong>Frontend</strong>: <a href=https://beeware.org/project/toga/>Toga</a>, a Python-native, OS-native GUI toolkit.</li><li><strong>Backend</strong>: <a href=https://flask.palletsprojects.com/en/stable/>Flask</a>, a lightweight web framework to host the AI models.</li><li><strong>Object Detection and Classification</strong>: <a href=https://www.v7labs.com/blog/yolo-object-detection>YOLO</a>, a widely used object detection model known for its speed and accuracy.</li><li><strong>Computer Vision Dataset</strong>: <a href=https://roboflow.com/>Roboflow</a>, used to train the YOLO model.</li><li><strong>Integration</strong>: Frontend and backend components communicate via a <a href=https://restfulapi.net/>REST API</a>.</li></ul><h2 id=project-structure>Project Structure<a hidden class=anchor aria-hidden=true href=#project-structure>#</a></h2><p>Here&rsquo;s an outline of the application&rsquo;s structure.</p><pre tabindex=0><code>contactsnap/
├── backend/
│   ├── app.py                  # Flask backend API
│   ├── inference/
│   │   ├── detect_classify.py  # YOLO/CNN detection and classification pipeline
│   │   └── models/
│   │       └── [model files]   # Model weights go here (nominally in *.pt format)
│
├── frontend/
│   ├── app.py                  # Toga GUI application
│   ├── uploads/                # uploaded images are saved here
│   └── results/                # annotated images are saved here
└── app.py                      # Launches frontend and backend
</code></pre><h2 id=learning-process>Learning Process<a hidden class=anchor aria-hidden=true href=#learning-process>#</a></h2><p>I also experimented with transfer learning. I first trained my YOLO model to identify relatively clean characters as objects using <a href=https://universe.roboflow.com/alphabettraining/character-detection-iis85>alphabettraining-iis85</a>, and then fine-tuned it for handwritten digits using <a href=https://universe.roboflow.com/cscai-o5oyu/handwriting-recognition-xyekz>cscai-o5oyu</a>. I &ldquo;froze&rdquo; the first 10 layers of the YOLO model to accelerate learning, assuming that the initial run had already learned the basic structure of digit objects and only needed fine-tuning to handle the variability of handwritten digits.</p><h3 id=learning-the-structure-of-digits>Learning the Structure of Digits<a hidden class=anchor aria-hidden=true href=#learning-the-structure-of-digits>#</a></h3><p>Below are the training and validation curves from the first training run, during which I trained the full model on digit objects. Note that both the training and validation loss decrease steadily. By the end, the validation loss is just above 1.</p><img src=/img/2025/contactsnapp/learning_results_a.png width=70%><h3 id=fine-tuning-for-handwritten-digits>Fine-tuning for Handwritten Digits<a hidden class=anchor aria-hidden=true href=#fine-tuning-for-handwritten-digits>#</a></h3><p>Below are the training and validation curves from the second training run, where I froze the first 10 layers of the model and focused mainly on optimizing the output layer. Note that both training and validation loss decline further than in the first run. By the end, the validation loss is around 0.5.</p><img src=/img/2025/contactsnapp/learning_results_b.png width=70%><h2 id=post-processing>Post-processing<a hidden class=anchor aria-hidden=true href=#post-processing>#</a></h2><p>To filter out non-phone-number elements, I developed a custom post-processing technique that only returns digit groups that are closely spaced horizontally.</p><p>As shown below, this successfully filters out letters that were mistakenly identified as part of the phone number:</p><div><img src=/img/2025/contactsnapp/output_with_labels_nopost.jpg width=30% style=display:inline-block>
<img src=/img/2025/contactsnapp/output_with_labels_post.jpg width=30% style=display:inline-block></div><h2 id=building-the-app-with-briefcase>Building the App with Briefcase<a hidden class=anchor aria-hidden=true href=#building-the-app-with-briefcase>#</a></h2><p>I used Briefcase to build the app. If you want to run the app yourself, make sure Python and Briefcase are installed:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install briefcase
</span></span></code></pre></div><p>Create the project:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>briefcase create
</span></span></code></pre></div><p>Build the app:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>briefcase build
</span></span></code></pre></div><p>Run the app:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>briefcase run
</span></span></code></pre></div><p>I don&rsquo;t pay the $99/year fee for an Apple Developer account, so I didn&rsquo;t distribute the app officially. However, if you&rsquo;re so inclined, this command will package it for distribution:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>briefcase package
</span></span></code></pre></div><h2 id=future-improvements>Future Improvements<a hidden class=anchor aria-hidden=true href=#future-improvements>#</a></h2><ul><li>The model still makes mistakes, especially with handwritten digits and under poor lighting conditions. I plan to improve the detection and classification models.</li><li>Develop a fully functional mobile app version.</li><li>Add an autosave feature to store detected phone numbers directly in the mobile contact list.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/ai/>Ai</a></li></ul></footer></article></main><footer class=site-footer><div class=footer-links><a href=/tags>tags</a>
<a href=/categories>categories</a></div><div class=container><p>Disclaimer: Views expressed here are my own and do not represent the opinions of my associates or my employer.</p><p>&copy; tjards 2025 |
Licenced under <a href=https://creativecommons.org/licenses/by/4.0/ target=_blank>Creative Commons</a>.</p><p>Built with <a href=https://gohugo.io/ target=_blank>Hugo</a>
using <a href=https://github.com/adityatelange/hugo-PaperMod target=_blank>PaperMod</a> theme.</p></footer></body></html>