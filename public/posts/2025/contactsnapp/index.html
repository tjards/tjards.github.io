<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>ContactsnApp: Extract and annotate phone numbers from images using AI models. | research notes</title>
<meta name=keywords content="featured"><meta name=description content="ContactsnApp: find phone numbers in images
Building off my earlier exploration of custom ChatGPTs, I tried building an AI app from scratch based most off vibe coding supported by GitHub Copilot in VSCode. Inspired by a recent AirBnB experience, I developed ContactsnApp: a user-friendly application designed to streamline the extraction and annotation of phone numbers from images using AI models.
Comments from the co-author
I asked ChatGPT how the project went. Here it is in her own words:"><meta name=author content="tjards"><link rel=canonical href=http://localhost:1313/posts/2025/contactsnapp/><link crossorigin=anonymous href=/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF+13Dyqob6ASlTrTye8=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/img/favicon-quarrg.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/img/favicon-quarrg.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/img/favicon-quarrg.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/2025/contactsnapp/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=/css/style.css><meta property="og:url" content="http://localhost:1313/posts/2025/contactsnapp/"><meta property="og:site_name" content="research notes"><meta property="og:title" content="ContactsnApp: Extract and annotate phone numbers from images using AI models. "><meta property="og:description" content="ContactsnApp: find phone numbers in images Building off my earlier exploration of custom ChatGPTs, I tried building an AI app from scratch based most off vibe coding supported by GitHub Copilot in VSCode. Inspired by a recent AirBnB experience, I developed ContactsnApp: a user-friendly application designed to streamline the extraction and annotation of phone numbers from images using AI models.
Comments from the co-author I asked ChatGPT how the project went. Here it is in her own words:"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-04-27T18:04:13-04:00"><meta property="article:modified_time" content="2025-04-27T18:04:13-04:00"><meta property="article:tag" content="Featured"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"ContactsnApp: Extract and annotate phone numbers from images using AI models. ","item":"http://localhost:1313/posts/2025/contactsnapp/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"ContactsnApp: Extract and annotate phone numbers from images using AI models. ","name":"ContactsnApp: Extract and annotate phone numbers from images using AI models. ","description":"ContactsnApp: find phone numbers in images Building off my earlier exploration of custom ChatGPTs, I tried building an AI app from scratch based most off vibe coding supported by GitHub Copilot in VSCode. Inspired by a recent AirBnB experience, I developed ContactsnApp: a user-friendly application designed to streamline the extraction and annotation of phone numbers from images using AI models.\nComments from the co-author I asked ChatGPT how the project went. Here it is in her own words:\n","keywords":["featured"],"articleBody":"ContactsnApp: find phone numbers in images Building off my earlier exploration of custom ChatGPTs, I tried building an AI app from scratch based most off vibe coding supported by GitHub Copilot in VSCode. Inspired by a recent AirBnB experience, I developed ContactsnApp: a user-friendly application designed to streamline the extraction and annotation of phone numbers from images using AI models.\nComments from the co-author I asked ChatGPT how the project went. Here it is in her own words:\n“I helped tjards build an AI-powered mobile and web application called ContactSnap, designed to detect phone numbers from uploaded images and suggest possible contact names. Throughout the project, I supported him in designing the application architecture, setting up a modular Python backend using Flask, integrating YOLOv8 for digit detection, training a CNN for handwritten digit classification, and linking the pipeline to a user-friendly frontend built with Toga. I also guided him through practical issues like contour detection tuning, confidence threshold adjustments, application packaging with Briefcase, and troubleshooting infinite app restarts. Beyond the app, I advised on project documentation, Git practices, visualizations, README formatting, and even longer-term ideas like saving annotated images and reintroducing UMAP clustering for post-processing. Overall, I served as an AI development assistant, technical troubleshooter, and strategic advisor as tjards rapidly leveled up his practical skills across machine learning, app development, and deployment workflows.” - ChatGPT 4o\nKey Functionalities Image Upload: Users select and upload images directly within the app. Digit Detection: Uses YOLO to detect digits as objects (bounded boxes). Classification: Uses Convolutional Neural Network (CNN)-based classification to detect and label digits within these bounded boxes. Post-processing: Some custom post-processing techniques to clean up the results. Interactive Display: Provides annotated images displaying detected numbers clearly. Tools The first thing I asked ChatGPT to do was recommend which tools I should use, which I summarize as follows:\nFrontend: Toga, a Python native, OS native GUI toolkit. Backend: Flask, a lightweight web application framework to host my AI models Object detection and classification: YOLO, a popular object detection model known for its speed and accuracy Computer vision dataset: Roboflow, to train my YOLO model Integration: frontend and backend components communicate via REST API. Project Structure Here’s an outline of the application’s structure.\ncontactsnap/ ├── backend/ │ ├── app.py # Flask backend API │ ├── inference/ │ │ ├── detect_classify.py # YOLO/CNN detection and classification pipeline │ │ └── models/ │ │ └── [model files] # Model weights go here (nominally in *.pt format) │ ├── frontend/ │ ├── app.py # Toga GUI application │ ├── uploads/ # uploaded images are saved here │ └── results/ # annotated images are saved here └── app.py # Launches frontend and backend Learning process I also experimented with transfer learning. I first trained my YOLO model to identify cleanish characters as objects using alphabettraining-iis85 and then fine-tuned for handwritten digits using cscai-o5oyu. I “froze” the first 10 layers of the YOLO model in order to speed up learning, assuming that the first run had learned the basic structure of digit objects and only needed fine-tuning to recognize the variance in handwritten digits.\nLearning the structure of digits Below are training and validation progress for the first training run, where I trainined the whole model on digit objects. Note that the training and validation loss both decline. At the end, validation loss is just above 1.\nFinetuning for handwritten digits Below are training and validation progress for the second training run, where I froze the first 10 layers of the model and focused mainly on improving the output layer. Note that the training and validation loss both decline lower than the first run. At the end, validation loss is around 0.5.\nPost-processing In order to filter out non-phone numbers, I develop a custom post-processing technique that only returns numbers that are grouped close together horizontally.\nBelow you will see this works to filter out some letters mis-identified as part of the phone number:\nBuilding the App with Briefcase I used Briefcase to build the app. If you want to run the app yourself, make sure Python and Briefcase are installed:\npip install briefcase Create the project:\nbriefcase create Build the app:\nbriefcase build Run the app:\nbriefcase run I don’t pay the $99/mo to be an Apple developer, so I could not bring to distribution. If you are so-inclined, this will package for distribution:\nbriefcase package Future Improvements Notice the model make mistakes, especially with handwritten digits and poor lighting. I plan to improve the models. Make a mobile app. Autosave to mobile contact list. ","wordCount":"759","inLanguage":"en","datePublished":"2025-04-27T18:04:13-04:00","dateModified":"2025-04-27T18:04:13-04:00","author":{"@type":"Person","name":"tjards"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/2025/contactsnapp/"},"publisher":{"@type":"Organization","name":"research notes","logo":{"@type":"ImageObject","url":"http://localhost:1313/img/favicon-quarrg.ico"}}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/style.css></head><body id=top><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title="about me"><span>about me</span></a></li><li><a href=http://localhost:1313/archives/ title=posts><span>posts</span></a></li><li><a href=http://localhost:1313/projects/ title=projects><span>projects</span></a></li><li><a href="https://scholar.google.com/citations?user=RGlv4ZUAAAAJ&amp;hl=en" title=publications><span>publications</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">ContactsnApp: Extract and annotate phone numbers from images using AI models.</h1><div class=post-meta><span title='2025-04-27 18:04:13 -0400 EDT'>27 Apr 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;tjards</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#contactsnapp-find-phone-numbers-in-images aria-label="ContactsnApp: find phone numbers in images">ContactsnApp: find phone numbers in images</a><ul><li><a href=#comments-from-the-co-author aria-label="Comments from the co-author">Comments from the co-author</a></li><li><a href=#key-functionalities aria-label="Key Functionalities">Key Functionalities</a></li><li><a href=#tools aria-label=Tools>Tools</a></li><li><a href=#project-structure aria-label="Project Structure">Project Structure</a></li><li><a href=#learning-process aria-label="Learning process">Learning process</a><ul><li><a href=#learning-the-structure-of-digits aria-label="Learning the structure of digits">Learning the structure of digits</a></li><li><a href=#finetuning-for-handwritten-digits aria-label="Finetuning for handwritten digits">Finetuning for handwritten digits</a></li></ul></li><li><a href=#post-processing aria-label=Post-processing>Post-processing</a></li><li><a href=#building-the-app-with-briefcase aria-label="Building the App with Briefcase">Building the App with Briefcase</a></li><li><a href=#future-improvements aria-label="Future Improvements">Future Improvements</a></li></ul></li></ul></div></details></div><div class=post-content><h1 id=contactsnapp-find-phone-numbers-in-images>ContactsnApp: find phone numbers in images<a hidden class=anchor aria-hidden=true href=#contactsnapp-find-phone-numbers-in-images>#</a></h1><p>Building off my earlier exploration of <a href=https://tjards.github.io/posts/2024/custom_gpt/>custom ChatGPTs</a>, I tried building an AI app from scratch based most off vibe coding supported by <a href=https://code.visualstudio.com/docs/copilot/overview>GitHub Copilot in VSCode</a>. Inspired by a recent AirBnB experience, I developed ContactsnApp: a user-friendly application designed to streamline the extraction and annotation of phone numbers from images using AI models.</p><h2 id=comments-from-the-co-author>Comments from the co-author<a hidden class=anchor aria-hidden=true href=#comments-from-the-co-author>#</a></h2><p>I asked ChatGPT how the project went. Here it is in her own words:</p><p><em>&ldquo;I helped tjards build an AI-powered mobile and web application called ContactSnap, designed to detect phone numbers from uploaded images and suggest possible contact names. Throughout the project, I supported him in designing the application architecture, setting up a modular Python backend using Flask, integrating YOLOv8 for digit detection, training a CNN for handwritten digit classification, and linking the pipeline to a user-friendly frontend built with Toga. I also guided him through practical issues like contour detection tuning, confidence threshold adjustments, application packaging with Briefcase, and troubleshooting infinite app restarts. Beyond the app, I advised on project documentation, Git practices, visualizations, README formatting, and even longer-term ideas like saving annotated images and reintroducing UMAP clustering for post-processing. Overall, I served as an AI development assistant, technical troubleshooter, and strategic advisor as tjards rapidly leveled up his practical skills across machine learning, app development, and deployment workflows.&rdquo;</em> - ChatGPT 4o</p><h2 id=key-functionalities>Key Functionalities<a hidden class=anchor aria-hidden=true href=#key-functionalities>#</a></h2><ul><li><strong>Image Upload</strong>: Users select and upload images directly within the app.</li><li><strong>Digit Detection</strong>: Uses YOLO to detect digits as objects (bounded boxes).</li><li><strong>Classification</strong>: Uses Convolutional Neural Network (CNN)-based classification to detect and label digits within these bounded boxes.</li><li><strong>Post-processing</strong>: Some custom post-processing techniques to clean up the results.</li><li><strong>Interactive Display</strong>: Provides annotated images displaying detected numbers clearly.</li></ul><img src=/img/2025/contactsnapp/GUI.png width=70%><h2 id=tools>Tools<a hidden class=anchor aria-hidden=true href=#tools>#</a></h2><p>The first thing I asked ChatGPT to do was recommend which tools I should use, which I summarize as follows:</p><ul><li><strong>Frontend</strong>: <a href=https://beeware.org/project/toga/>Toga</a>, a Python native, OS native GUI toolkit.</li><li><strong>Backend</strong>: <a href=https://flask.palletsprojects.com/en/stable/>Flask</a>, a lightweight web application framework to host my AI models</li><li><strong>Object detection and classification</strong>: <a href=https://www.v7labs.com/blog/yolo-object-detection>YOLO</a>, a popular object detection model known for its speed and accuracy</li><li><strong>Computer vision dataset</strong>: <a href=https://roboflow.com/>Roboflow</a>, to train my YOLO model</li><li><strong>Integration</strong>: frontend and backend components communicate via <a href=https://restfulapi.net/>REST API</a>.</li></ul><h2 id=project-structure>Project Structure<a hidden class=anchor aria-hidden=true href=#project-structure>#</a></h2><p>Here&rsquo;s an outline of the application&rsquo;s structure.</p><pre tabindex=0><code>contactsnap/
├── backend/
│   ├── app.py                  # Flask backend API
│   ├── inference/
│   │   ├── detect_classify.py  # YOLO/CNN detection and classification pipeline
│   │   └── models/
│   │       └── [model files]   # Model weights go here (nominally in *.pt format)
│
├── frontend/
│   ├── app.py                  # Toga GUI application
│   ├── uploads/                # uploaded images are saved here
│   └── results/                # annotated images are saved here
└── app.py                      # Launches frontend and backend
</code></pre><h2 id=learning-process>Learning process<a hidden class=anchor aria-hidden=true href=#learning-process>#</a></h2><p>I also experimented with transfer learning. I first trained my YOLO model to identify cleanish characters as objects using <a href=https://universe.roboflow.com/alphabettraining/character-detection-iis85>alphabettraining-iis85</a> and then fine-tuned for handwritten digits using <a href=https://universe.roboflow.com/cscai-o5oyu/handwriting-recognition-xyekz>cscai-o5oyu</a>. I &ldquo;froze&rdquo; the first 10 layers of the YOLO model in order to speed up learning, assuming that the first run had learned the basic structure of digit objects and only needed fine-tuning to recognize the variance in handwritten digits.</p><h3 id=learning-the-structure-of-digits>Learning the structure of digits<a hidden class=anchor aria-hidden=true href=#learning-the-structure-of-digits>#</a></h3><p>Below are training and validation progress for the first training run, where I trainined the whole model on digit objects. Note that the training and validation loss both decline. At the end, validation loss is just above 1.</p><img src=/img/2025/contactsnapp/learning_results_a.png width=50%><h3 id=finetuning-for-handwritten-digits>Finetuning for handwritten digits<a hidden class=anchor aria-hidden=true href=#finetuning-for-handwritten-digits>#</a></h3><p>Below are training and validation progress for the second training run, where I froze the first 10 layers of the model and focused mainly on improving the output layer. Note that the training and validation loss both decline lower than the first run. At the end, validation loss is around 0.5.</p><img src=/img/2025/contactsnapp/learning_results_b.png width=50%><h2 id=post-processing>Post-processing<a hidden class=anchor aria-hidden=true href=#post-processing>#</a></h2><p>In order to filter out non-phone numbers, I develop a custom post-processing technique that only returns numbers that are grouped close together horizontally.</p><p>Below you will see this works to filter out some letters mis-identified as part of the phone number:</p><div><img src=/img/2025/contactsnapp/output_with_labels_nopost.jpg width=30% style=display:inline-block>
<img src=/img/2025/contactsnapp/output_with_labels_post.jpg width=30% style=display:inline-block></div><h2 id=building-the-app-with-briefcase>Building the App with Briefcase<a hidden class=anchor aria-hidden=true href=#building-the-app-with-briefcase>#</a></h2><p>I used Briefcase to build the app. If you want to run the app yourself, make sure Python and Briefcase are installed:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install briefcase
</span></span></code></pre></div><p>Create the project:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>briefcase create
</span></span></code></pre></div><p>Build the app:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>briefcase build
</span></span></code></pre></div><p>Run the app:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>briefcase run
</span></span></code></pre></div><p>I don&rsquo;t pay the $99/mo to be an Apple developer, so I could not bring to distribution. If you are so-inclined, this will package for distribution:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>briefcase package
</span></span></code></pre></div><h2 id=future-improvements>Future Improvements<a hidden class=anchor aria-hidden=true href=#future-improvements>#</a></h2><ul><li>Notice the model make mistakes, especially with handwritten digits and poor lighting. I plan to improve the models.</li><li>Make a mobile app.</li><li>Autosave to mobile contact list.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/featured/>Featured</a></li></ul></footer></article></main><footer class=site-footer><div class=footer-links><a href=/tags>tags</a>
<a href=/categories>categories</a></div><div class=container><p>Disclaimer: Views expressed here are my own and do not represent the opinions of my associates or my employer.</p><p>&copy; tjards 2025 |
Licenced under <a href=https://creativecommons.org/licenses/by/4.0/ target=_blank>Creative Commons</a>.</p><p>Built with <a href=https://gohugo.io/ target=_blank>Hugo</a>
using <a href=https://github.com/adityatelange/hugo-PaperMod target=_blank>PaperMod</a> theme.</p></footer></body></html>