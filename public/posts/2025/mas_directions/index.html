<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Mas_directions | thoughts on my mind</title>
<meta name=keywords content><meta name=description content="Multi-agent Control is Quietly Entering a New Theoretical Era
In late 2021, while the world was still grappling with a global pandemic, I was searching for ways to stay productive and—well—sane. Like many young researchers, I wanted a fresh direction that felt relevant to a changing world and built on what I already knew. Having spent years studying dynamical systems, control theory, and reinforcement learning, extending these ideas to more complex multi-agent settings seemed like a natural next step. I had always been drawn to Reynolds’s early biologically inspired bird-flocking work [2], and it eventually led me into the rich and fascinating world of multi-agent systems (MAS)."><meta name=author content="tjards"><link rel=canonical href=http://localhost:1313/posts/2025/mas_directions/><link crossorigin=anonymous href=/assets/css/stylesheet.b93646cb73c0e3fa8adbd074f75a838e4ff61605b76591de56d80fa16276c922.css integrity="sha256-uTZGy3PA4/qK29B091qDjk/2FgW3ZZHeVtgPoWJ2ySI=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/img/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/img/favicon16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/img/favicon32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/2025/mas_directions/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:url" content="http://localhost:1313/posts/2025/mas_directions/"><meta property="og:site_name" content="thoughts on my mind"><meta property="og:title" content="Mas_directions"><meta property="og:description" content="Multi-agent Control is Quietly Entering a New Theoretical Era In late 2021, while the world was still grappling with a global pandemic, I was searching for ways to stay productive and—well—sane. Like many young researchers, I wanted a fresh direction that felt relevant to a changing world and built on what I already knew. Having spent years studying dynamical systems, control theory, and reinforcement learning, extending these ideas to more complex multi-agent settings seemed like a natural next step. I had always been drawn to Reynolds’s early biologically inspired bird-flocking work [2], and it eventually led me into the rich and fascinating world of multi-agent systems (MAS)."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-11-16T11:31:32-05:00"><meta property="article:modified_time" content="2025-11-16T11:31:32-05:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"Mas_directions","item":"http://localhost:1313/posts/2025/mas_directions/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Mas_directions","name":"Mas_directions","description":"Multi-agent Control is Quietly Entering a New Theoretical Era In late 2021, while the world was still grappling with a global pandemic, I was searching for ways to stay productive and—well—sane. Like many young researchers, I wanted a fresh direction that felt relevant to a changing world and built on what I already knew. Having spent years studying dynamical systems, control theory, and reinforcement learning, extending these ideas to more complex multi-agent settings seemed like a natural next step. I had always been drawn to Reynolds’s early biologically inspired bird-flocking work [2], and it eventually led me into the rich and fascinating world of multi-agent systems (MAS).\n","keywords":[],"articleBody":"Multi-agent Control is Quietly Entering a New Theoretical Era In late 2021, while the world was still grappling with a global pandemic, I was searching for ways to stay productive and—well—sane. Like many young researchers, I wanted a fresh direction that felt relevant to a changing world and built on what I already knew. Having spent years studying dynamical systems, control theory, and reinforcement learning, extending these ideas to more complex multi-agent settings seemed like a natural next step. I had always been drawn to Reynolds’s early biologically inspired bird-flocking work [2], and it eventually led me into the rich and fascinating world of multi-agent systems (MAS).\nWhat I discovered was a quiet revolution underway. For nearly two decades, the MAS community operated inside a beautifully structured theoretical framework-one grounded in graph Laplacians, consensus protocols, and Lyapunov stability proofs. At first, I found it frustrating to develop new insights beyond this rigid structure-a feeling exacerbated by a deluge of papers that seemed to rehash the same ideas for niche applications… or just find reasons to apply machine learning to problems already solved by classical methods. However, beneath all this well-structured noise and apparent stability, I discovered a new frontier already being explored. This new frontier was characterized by operations in hidden spaces.\nThe Previous Frontier The paper that first caught my attention was Olfati-Saber’s 2006 work on flocking for multi-agent dynamic systems [5]. I found the synthesis of graph theory, control theory, and distributed algorithms elegant. Watching simple, strict rules generate elaborate, scalable group behaviours was captivating. What I did not appreciate at the time, however, was the broader context surrounding this work.\nIf you were doing distributed control research between 2003 and 2010, you were living through a golden age. Olfati-Saber’s paper was among the most prominent in a wave of foundational contributions exploring how to coordinate multiple agents effectively. Building on earlier ideas from Fiedler [1], Jadbabaie et al. [3], and others [4–6], this period saw a flurry of activity that culminated in the comprehensive texts by Ren \u0026 Beard [7], Mesbahi \u0026 Egerstedt [8], and Ren \u0026 Cao [9]. Collectively, these efforts established the theoretical foundations of modern multi-agent systems.\nRoughly, I would summarize the key insights from this era as follows:\nAgents can generally be modeled at particles in free space using double-integrator dynamics.\nThe relationships between agents can be captured using graph theory, with nodes representing agents and edges representing their interactions.\nWe can build Lyapunov functions to examine the stability and convergence of the overall system.\nControl laws can be designed using simple rules of cohesion, separation, and alignment based on local information.\nThese control laws typically correspond to gradient descent flows of well-chosen Lyapunov functions.\nReferences Foundational 1. F. Fiedler (1973).\nAlgebraic connectivity of graphs. Czechoslovak Mathematical Journal.\n2. C. W. Reynolds (1987).\nFlocks, herds and schools: A distributed behavioral model. SIGGRAPH ‘87: Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques.\n3. A. Jadbabaie, J. Lin, \u0026 A. S. Morse (2003).\nCoordination of groups of mobile autonomous agents using nearest neighbor rules. IEEE Transactions on Automatic Control.\n4. R. Olfati-Saber \u0026 R. M. Murray (2004).\nConsensus problems in networks of agents with switching topology and time-delays. IEEE Transactions on Automatic Control.\n5. R. Olfati-Saber (2006).\nFlocking for multi-agent dynamic systems: algorithms and theory. IEEE Transactions on Automatic Control.\n6. R. Olfati-Saber, J. A. Fax, \u0026 R. M. Murray (2007).\nConsensus and cooperation in networked multi-agent systems. Proceedings of the IEEE.\n7. W. Ren \u0026 R. Beard (2008).\nDistributed Consensus in Multi-Vehicle Cooperative Control. Springer.\n8. M. Mesbahi \u0026 M. Egerstedt (2010).\nGraph Theoretic Methods in Multi-Agent Networks. Princeton University Press.\n9. W. Ren \u0026 Y. Cao (2011).\nDistributed Coordination of Multi-Agent Networks: Emergent Problems, Models, and Issues. Springer.\nLearning 10. K. S. Narendra \u0026 M. A. L. Thathachar (1974).\nLearning automata – A survey. IEEE Transactions on Systems, Man, and Cybernetics.\n11. L. Busoniu, R. Babuska, B. De Schutter, \u0026 D. Ernst (2010).\nReinforcement Learning and Dynamic Programming Using Function Approximators. CRC Press.\n12. Y. Yang, R. Luo, M. Li, M. Zhou, W. Zhang, \u0026 J. Wang (2018).\nMean field multi-agent reinforcement learning. Proceedings of ICML.\n13. B. Recht (2019).\nA tour of reinforcement learning: The view from continuous control. Annual Review of Control, Robotics, and Autonomous Systems.\n14. K. Zhang, Z. Yang, \u0026 T. Başar (2021).\nMulti-agent reinforcement learning: A selective overview. In Handbook of Reinforcement Learning and Control. Springer.\n15. G. Jing, H. Bai, J. George, A. Chakrabortty, \u0026 P. K. Sharma (2024).\nDistributed multiagent reinforcement learning based on graph-induced local value functions. IEEE Transactions on Automatic Control.\nHidden Spaces 16. B. O. Koopman (1931).\nHamiltonian systems and transformation in Hilbert space. Proceedings of the National Academy of Sciences.\n17. C. W. Rowley, I. Mezić, S. Bagheri, P. Schlatter, \u0026 D. S. Henningson (2009).\nSpectral analysis of nonlinear flows. Journal of Fluid Mechanics.\n18. B. Lusch, J. N. Kutz, \u0026 S. L. Brunton (2018).\nDeep learning for universal linear embeddings of nonlinear dynamics. Nature Communications.\n19. M. Korda \u0026 I. Mezić (2018).\nLinear predictors for nonlinear dynamical systems: Koopman operator meets model predictive control. Automatica.\n20. J. L. Proctor, S. L. Brunton, \u0026 J. N. Kutz (2018).\nGeneralizing Koopman theory to allow for inputs and control. SIAM Journal on Applied Dynamical Systems.\n21. P. T. Jardine \u0026 S. G. Givigi (2025).\nEmergent homeomorphic curves in swarms. Automatica, Vol. 176.\n","wordCount":"902","inLanguage":"en","datePublished":"2025-11-16T11:31:32-05:00","dateModified":"2025-11-16T11:31:32-05:00","author":{"@type":"Person","name":"tjards"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/2025/mas_directions/"},"publisher":{"@type":"Organization","name":"thoughts on my mind","logo":{"@type":"ImageObject","url":"http://localhost:1313/img/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title="about me"><span>about me</span></a></li><li><a href=http://localhost:1313/archives/ title=posts><span>posts</span></a></li><li><a href=http://localhost:1313/projects/ title=projects><span>projects</span></a></li><li><a href="https://scholar.google.com/citations?user=RGlv4ZUAAAAJ&amp;hl=en" title=publications><span>publications</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><div class=content-with-sidebar><div class=content-main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Mas_directions
<span class=entry-hint title=Draft><svg height="35" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h1><div class=post-meta><span title='2025-11-16 11:31:32 -0500 EST'>16 Nov 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;tjards</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#multi-agent-control-is-quietly-entering-a-new-theoretical-era aria-label="Multi-agent Control is Quietly Entering a New Theoretical Era">Multi-agent Control is Quietly Entering a New Theoretical Era</a><ul><li><a href=#the-previous-frontier aria-label="The Previous Frontier">The Previous Frontier</a></li><li><a href=#references aria-label=References>References</a><ul><li><a href=#foundational aria-label=Foundational>Foundational</a></li><li><a href=#learning aria-label=Learning>Learning</a></li><li><a href=#hidden-spaces aria-label="Hidden Spaces">Hidden Spaces</a></li></ul></li></ul></li></ul></div></details></div><div class=post-content><h1 id=multi-agent-control-is-quietly-entering-a-new-theoretical-era>Multi-agent Control is Quietly Entering a New Theoretical Era<a hidden class=anchor aria-hidden=true href=#multi-agent-control-is-quietly-entering-a-new-theoretical-era>#</a></h1><p>In late 2021, while the world was still grappling with a global pandemic, I was searching for ways to stay productive and—well—sane. Like many young researchers, I wanted a fresh direction that felt relevant to a changing world and built on what I already knew. Having spent years studying dynamical systems, control theory, and reinforcement learning, extending these ideas to more complex multi-agent settings seemed like a natural next step. I had always been drawn to Reynolds’s early biologically inspired bird-flocking work [2], and it eventually led me into the rich and fascinating world of multi-agent systems (MAS).</p><p>What I discovered was a quiet revolution underway. For nearly two decades, the MAS community operated inside a beautifully structured theoretical framework-one grounded in graph Laplacians, consensus protocols, and Lyapunov stability proofs. At first, I found it frustrating to develop new insights beyond this rigid structure-a feeling exacerbated by a deluge of papers that seemed to rehash the same ideas for niche applications&mldr; or just find reasons to apply machine learning to problems already solved by classical methods. However, beneath all this well-structured noise and apparent stability, I discovered a new frontier already being explored. This new frontier was characterized by operations in hidden spaces.</p><h2 id=the-previous-frontier>The Previous Frontier<a hidden class=anchor aria-hidden=true href=#the-previous-frontier>#</a></h2><p>The paper that first caught my attention was Olfati-Saber’s 2006 work on flocking for multi-agent dynamic systems [5]. I found the synthesis of graph theory, control theory, and distributed algorithms elegant. Watching simple, strict rules generate elaborate, scalable group behaviours was captivating. What I did not appreciate at the time, however, was the broader context surrounding this work.</p><p>If you were doing distributed control research between 2003 and 2010, you were living through a golden age. Olfati-Saber’s paper was among the most prominent in a wave of foundational contributions exploring how to coordinate multiple agents effectively. Building on earlier ideas from Fiedler [1], Jadbabaie et al. [3], and others [4–6], this period saw a flurry of activity that culminated in the comprehensive texts by Ren & Beard [7], Mesbahi & Egerstedt [8], and Ren & Cao [9]. Collectively, these efforts established the theoretical foundations of modern multi-agent systems.</p><p>Roughly, I would summarize the key insights from this era as follows:</p><ol><li><p>Agents can generally be modeled at particles in free space using double-integrator dynamics.</p></li><li><p>The relationships between agents can be captured using graph theory, with nodes representing agents and edges representing their interactions.</p></li><li><p>We can build Lyapunov functions to examine the stability and convergence of the overall system.</p></li><li><p>Control laws can be designed using simple rules of cohesion, separation, and alignment based on local information.</p></li><li><p>These control laws typically correspond to gradient descent flows of well-chosen Lyapunov functions.</p></li></ol><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><h3 id=foundational>Foundational<a hidden class=anchor aria-hidden=true href=#foundational>#</a></h3><p><strong>1. F. Fiedler (1973).</strong><br><a href=https://eudml.org/doc/12723><em>Algebraic connectivity of graphs</em></a>. <em>Czechoslovak Mathematical Journal</em>.</p><p><strong>2. C. W. Reynolds (1987).</strong><br><a href=https://doi.org/10.1145/37401.37406><em>Flocks, herds and schools: A distributed behavioral model</em></a>. <em>SIGGRAPH &lsquo;87: Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques</em>.</p><p><strong>3. A. Jadbabaie, J. Lin, & A. S. Morse (2003).</strong><br><a href=https://doi.org/10.1109/TAC.2003.812781><em>Coordination of groups of mobile autonomous agents using nearest neighbor rules</em></a>. <em>IEEE Transactions on Automatic Control</em>.</p><p><strong>4. R. Olfati-Saber & R. M. Murray (2004).</strong><br><a href=https://doi.org/10.1109/TAC.2004.834113><em>Consensus problems in networks of agents with switching topology and time-delays</em></a>. <em>IEEE Transactions on Automatic Control</em>.</p><p><strong>5. R. Olfati-Saber (2006).</strong><br><a href=https://doi.org/10.1109/TAC.2005.864190><em>Flocking for multi-agent dynamic systems: algorithms and theory</em></a>. <em>IEEE Transactions on Automatic Control</em>.</p><p><strong>6. R. Olfati-Saber, J. A. Fax, & R. M. Murray (2007).</strong><br><a href=https://doi.org/10.1109/JPROC.2006.887293><em>Consensus and cooperation in networked multi-agent systems</em></a>. <em>Proceedings of the IEEE</em>.</p><p><strong>7. W. Ren & R. Beard (2008).</strong><br><a href=https://link.springer.com/book/10.1007/978-1-84800-015-5><em>Distributed Consensus in Multi-Vehicle Cooperative Control</em></a>. Springer.</p><p><strong>8. M. Mesbahi & M. Egerstedt (2010).</strong><br><a href=https://doi.org/10.2307/j.ctt1287k9b><em>Graph Theoretic Methods in Multi-Agent Networks</em></a>. Princeton University Press.</p><p><strong>9. W. Ren & Y. Cao (2011).</strong><br><a href=https://link.springer.com/book/10.1007/978-0-85729-169-1><em>Distributed Coordination of Multi-Agent Networks: Emergent Problems, Models, and Issues</em></a>. Springer.</p><h3 id=learning>Learning<a hidden class=anchor aria-hidden=true href=#learning>#</a></h3><p><strong>10. K. S. Narendra & M. A. L. Thathachar (1974).</strong><br><a href=https://doi.org/10.1109/TSMC.1974.5408453><em>Learning automata – A survey</em></a>. <em>IEEE Transactions on Systems, Man, and Cybernetics</em>.</p><p><strong>11. L. Busoniu, R. Babuska, B. De Schutter, & D. Ernst (2010).</strong><br><a href=http://rlbook.busoniu.net/><em>Reinforcement Learning and Dynamic Programming Using Function Approximators</em></a>. CRC Press.</p><p><strong>12. Y. Yang, R. Luo, M. Li, M. Zhou, W. Zhang, & J. Wang (2018).</strong><br><a href=http://proceedings.mlr.press/v80/yang18d.html><em>Mean field multi-agent reinforcement learning</em></a>. <em>Proceedings of ICML</em>.</p><p><strong>13. B. Recht (2019).</strong><br><a href=https://doi.org/10.1146/annurev-control-053018-023825><em>A tour of reinforcement learning: The view from continuous control</em></a>. <em>Annual Review of Control, Robotics, and Autonomous Systems</em>.</p><p><strong>14. K. Zhang, Z. Yang, & T. Başar (2021).</strong><br><a href=https://link.springer.com/chapter/10.1007/978-3-030-60990-0_12><em>Multi-agent reinforcement learning: A selective overview</em></a>. In <em>Handbook of Reinforcement Learning and Control</em>. Springer.</p><p><strong>15. G. Jing, H. Bai, J. George, A. Chakrabortty, & P. K. Sharma (2024).</strong><br><a href=https://doi.org/10.1109/TAC.2024.3375248><em>Distributed multiagent reinforcement learning based on graph-induced local value functions</em></a>. <em>IEEE Transactions on Automatic Control</em>.</p><h3 id=hidden-spaces>Hidden Spaces<a hidden class=anchor aria-hidden=true href=#hidden-spaces>#</a></h3><p><strong>16. B. O. Koopman (1931).</strong><br><a href=https://doi.org/10.1073/pnas.17.5.315><em>Hamiltonian systems and transformation in Hilbert space</em></a>. <em>Proceedings of the National Academy of Sciences</em>.</p><p><strong>17. C. W. Rowley, I. Mezić, S. Bagheri, P. Schlatter, & D. S. Henningson (2009).</strong><br><a href=https://doi.org/10.1017/S0022112009992059><em>Spectral analysis of nonlinear flows</em></a>. <em>Journal of Fluid Mechanics</em>.</p><p><strong>18. B. Lusch, J. N. Kutz, & S. L. Brunton (2018).</strong><br><a href=https://www.nature.com/articles/s41467-018-07210-0><em>Deep learning for universal linear embeddings of nonlinear dynamics</em></a>. <em>Nature Communications</em>.</p><p><strong>19. M. Korda & I. Mezić (2018).</strong><br><a href=https://doi.org/10.1016/j.automatica.2018.03.046><em>Linear predictors for nonlinear dynamical systems: Koopman operator meets model predictive control</em></a>. <em>Automatica</em>.</p><p><strong>20. J. L. Proctor, S. L. Brunton, & J. N. Kutz (2018).</strong><br><a href=https://doi.org/10.1137/16M1062296><em>Generalizing Koopman theory to allow for inputs and control</em></a>. <em>SIAM Journal on Applied Dynamical Systems</em>.</p><p><strong>21. P. T. Jardine & S. G. Givigi (2025).</strong><br><a href=https://doi.org/10.1016/j.automatica.2024.112221><em>Emergent homeomorphic curves in swarms</em></a>. <em>Automatica</em>, Vol. 176.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></div><aside class=sidebar-recent><div class=sidebar-recent-inner><h3 class=sidebar-title>recent posts</h3><article class=sidebar-post><a class=sidebar-post-title href=/posts/2025/ivoryworks/>ivoryworks</a><div class=sidebar-post-meta><span class=sidebar-post-date>2025-11-28
</span><span class=sidebar-post-separator>·</span></span></div></article><article class=sidebar-post><a class=sidebar-post-title href=/posts/2025/density_of_honey/>The Density of Honey</a><div class=sidebar-post-meta><span class=sidebar-post-date>2025-11-23
</span><span class=sidebar-post-separator>·</span></span><div class=sidebar-post-category><span class=category-pill>personal</span></div></div></article><article class=sidebar-post><a class=sidebar-post-title href=/posts/2025/mas_directions/>Mas_directions</a><div class=sidebar-post-meta><span class=sidebar-post-date>2025-11-16
</span><span class=sidebar-post-separator>·</span></span><div class=sidebar-post-category><span class=category-pill>research</span></div></div></article></div></aside></div></main><footer class=site-footer><div class=footer-links><a href=/tags>tags</a>
<a href=/categories>categories</a></div><div class=container><p>Disclaimer: Views expressed here are my own and do not represent the opinions of my associates or my employer.</p><p>&copy; tjards 2025 |
Licenced under <a href=https://creativecommons.org/licenses/by/4.0/ target=_blank>Creative Commons</a>.</p><p>Built with <a href=https://gohugo.io/ target=_blank>Hugo</a>
using <a href=https://github.com/adityatelange/hugo-PaperMod target=_blank>PaperMod</a> theme.</p></footer></body></html>