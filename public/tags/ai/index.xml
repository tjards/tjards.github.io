<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Ai on research notes</title>
    <link>http://localhost:1313/tags/ai/</link>
    <description>Recent content in Ai on research notes</description>
    <generator>Hugo -- 0.146.5</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Sep 2025 17:18:41 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Future of AI is in Lower Dimensions</title>
      <link>http://localhost:1313/posts/2025/hypospace_learn/</link>
      <pubDate>Mon, 29 Sep 2025 17:18:41 -0400</pubDate>
      <guid>http://localhost:1313/posts/2025/hypospace_learn/</guid>
      <description>&lt;p&gt;In a recent interview with Lex Fridman entitled &amp;ldquo;Dark Matter of Intelligence and Self-Supervised Learning,&amp;rdquo; outspoken AI pioneer &lt;a href=&#34;http://yann.lecun.com/&#34;&gt;Yann Lecun&lt;/a&gt; suggested the next leap in Artificial Intelligence (AI) will come from learning in lower-dimensional latent spaces.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;You don&amp;rsquo;t predict pixels, you predict an abstract representation of pixels.&amp;rdquo;&lt;/em&gt; - Yann Lecun&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;What does he mean and how is it relevant to the future of AI?&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s back up and consider the context in which this statement was made. Yann was discussing the limitations of current AI systems, particularly those based on deep neural networks. In a &lt;a href=&#34;http://localhost:1313/posts/2025/matrix_entropy&#34;&gt;previous article&lt;/a&gt;, we touched on one such example â€” Large Language Models (LLMs). LLMs have demonstrated impressive performance across an array of language-related tasks. So popular, a recent &lt;a href=&#34;https://arxiv.org/abs/2401.05749&#34;&gt;AWS study&lt;/a&gt; found a &amp;ldquo;shocking amount of the web&amp;rdquo; is already LLM-generated. This is problematic, as LLMs trained on this kind of synthetic content break down and lose their ability to generalize. A recent &lt;a href=&#34;https://www.nature.com/articles/s41586-024-07566-y&#34;&gt;Nature article&lt;/a&gt; described this &amp;ldquo;model collapse&amp;rdquo; phenomenon in detail.&lt;/p&gt;</description>
    </item>
    <item>
      <title>ContactsnApp: Extract and Annotate Phone Numbers from Images Using AI Models</title>
      <link>http://localhost:1313/posts/2025/contactsnapp/</link>
      <pubDate>Sun, 27 Apr 2025 18:04:13 -0400</pubDate>
      <guid>http://localhost:1313/posts/2025/contactsnapp/</guid>
      <description>&lt;p float=&#34;right&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/img/2025/contactsnapp/CsnApp.jpeg&#34; width=&#34;25%&#34; style=&#34;float: left; margin: 0 1em 0 0;&#34;/&gt;
&lt;/p&gt;
&lt;p&gt;Building on my earlier exploration of &lt;a href=&#34;https://tjards.github.io/posts/2024/custom_gpt/&#34;&gt;custom ChatGPTs&lt;/a&gt;, I tried building an AI app from scratch, primarily using vibe coding supported by &lt;a href=&#34;https://code.visualstudio.com/docs/copilot/overview&#34;&gt;GitHub Copilot in VSCode&lt;/a&gt;. Inspired by a recent Airbnb experience, I developed &lt;a href=&#34;https://github.com/tjards/ContactsnApp&#34;&gt;ContactsnApp&lt;/a&gt;: a user-friendly application designed to streamline the extraction and annotation of phone numbers from images using AI models.&lt;/p&gt;
&lt;h2 id=&#34;comments-from-the-co-author&#34;&gt;Comments from the Co-author&lt;/h2&gt;
&lt;p&gt;I asked ChatGPT how the project went. Here it is in her own words:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Co-doc: A Custom GPT Research Assistant</title>
      <link>http://localhost:1313/posts/2024/custom_gpt/</link>
      <pubDate>Wed, 25 Dec 2024 18:43:18 -0500</pubDate>
      <guid>http://localhost:1313/posts/2024/custom_gpt/</guid>
      <description>&lt;h2 id=&#34;key-points&#34;&gt;Key Points&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Built a custom ChatGPT to assist me with my research.&lt;/li&gt;
&lt;li&gt;Trained it on actual comments from peer-review.&lt;/li&gt;
&lt;li&gt;Received feedback on my proposed revisions.&lt;/li&gt;
&lt;li&gt;Overall impressed with its initial performance.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;One of my holiday projects this year was to play with some of the special features that come with the &lt;a href=&#34;https://chatgpt.com/&#34;&gt;OpenAI ChatGPT&lt;/a&gt; &lt;em&gt;Plus&lt;/em&gt; account. In additon to gaining access to better models and more reliable performance, the &lt;em&gt;Plus&lt;/em&gt; account allows you to create your own custom GPTs, tailored to your own needs.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
