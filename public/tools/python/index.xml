<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Python on research notes</title>
    <link>http://localhost:1313/tools/python/</link>
    <description>Recent content in Python on research notes</description>
    <generator>Hugo -- 0.146.5</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Sep 2025 17:18:41 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/tools/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Future of AI is in Lower Dimensions</title>
      <link>http://localhost:1313/posts/2025/hypospace_learn/</link>
      <pubDate>Mon, 29 Sep 2025 17:18:41 -0400</pubDate>
      <guid>http://localhost:1313/posts/2025/hypospace_learn/</guid>
      <description>&lt;p&gt;In a recent interview with Lex Fridman entitled &amp;ldquo;Dark Matter of Intelligence and Self-Supervised Learning,&amp;rdquo; outspoken AI pioneer &lt;a href=&#34;http://yann.lecun.com/&#34;&gt;Yann Lecun&lt;/a&gt; suggested the next leap in Artificial Intelligence (AI) will come from learning in lower-dimensional latent spaces.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;You don&amp;rsquo;t predict pixels, you predict an abstract representation of pixels.&amp;rdquo;&lt;/em&gt; - Yann Lecun&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;What does he mean and how is it relevant to the future of AI?&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s back up and consider the context in which this statement was made. Yann was discussing the limitations of current AI systems, particularly those based on deep neural networks. In a &lt;a href=&#34;http://localhost:1313/posts/2025/matrix_entropy&#34;&gt;previous article&lt;/a&gt;, we touched on one such example â€” Large Language Models (LLMs). LLMs have demonstrated impressive performance across an array of language-related tasks. So popular, a recent &lt;a href=&#34;https://arxiv.org/abs/2401.05749&#34;&gt;AWS study&lt;/a&gt; found a &amp;ldquo;shocking amount of the web&amp;rdquo; is already LLM-generated. This is problematic, as LLMs trained on this kind of synthetic content break down and lose their ability to generalize. A recent &lt;a href=&#34;https://www.nature.com/articles/s41586-024-07566-y&#34;&gt;Nature article&lt;/a&gt; described this &amp;ldquo;model collapse&amp;rdquo; phenomenon in detail.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Multi-agent Coordination Simulator</title>
      <link>http://localhost:1313/posts/2025/m-a_s/</link>
      <pubDate>Sun, 04 May 2025 07:04:13 -0400</pubDate>
      <guid>http://localhost:1313/posts/2025/m-a_s/</guid>
      <description>&lt;div style=&#34;display: flex; align-items: flex-start; gap: 1.5rem; margin: 1rem 0;&#34;&gt;
  &lt;!-- Left column --&gt;
  &lt;div style=&#34;flex: 0 0 25%;&#34;&gt;
    &lt;img src=&#34;http://localhost:1313/img/2025/m-a_s/m-a_s.png&#34; style=&#34;width: 100%; height: auto; border-radius: 4px;&#34; /&gt;
  &lt;/div&gt;
  &lt;!-- Right column --&gt;
  &lt;div style=&#34;flex: 1;&#34;&gt;
    &lt;p&gt;
      A fully open architecture implementation of modern multi-agent coordination techniques.
    &lt;/p&gt;
    &lt;p&gt;  
      Detailed description and code is available on
      &lt;a href=&#34;https://github.com/tjards/multi-agent_sim&#34;&gt;GitHub&lt;/a&gt;.
    &lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The project was used to validate theoretical results in the following publications:&lt;/p&gt;
&lt;div style=&#34;display: flex; align-items: flex-start; gap: 1.5rem; margin: 1rem 0;&#34;&gt;
  &lt;!-- Left column --&gt;
  &lt;div style=&#34;flex: 0 0 40%;&#34;&gt;
  Decentralized generation of lemniscate trajectories using local information
  &lt;/div&gt;
  &lt;!-- Right column --&gt;
  &lt;div style=&#34;flex: 1;&#34;&gt;
&lt;p&gt;&lt;a href=&#34;10.1109/TNSE.2022.3217460&#34;&gt;Flocks, Mobs, and Figure Eights: Swarming as a Lemniscatic Arch&lt;/a&gt; published in IEEE Transactions on Network Science and Engineering, Vol 10 (2), Mar 2023)&lt;/p&gt;</description>
    </item>
    <item>
      <title>ContactsnApp: Extract and Annotate Phone Numbers from Images Using AI Models</title>
      <link>http://localhost:1313/posts/2025/contactsnapp/</link>
      <pubDate>Sun, 27 Apr 2025 18:04:13 -0400</pubDate>
      <guid>http://localhost:1313/posts/2025/contactsnapp/</guid>
      <description>&lt;p float=&#34;right&#34;&gt;
  &lt;img src=&#34;http://localhost:1313/img/2025/contactsnapp/CsnApp.jpeg&#34; width=&#34;25%&#34; style=&#34;float: left; margin: 0 1em 0 0;&#34;/&gt;
&lt;/p&gt;
&lt;p&gt;Building on my earlier exploration of &lt;a href=&#34;https://tjards.github.io/posts/2024/custom_gpt/&#34;&gt;custom ChatGPTs&lt;/a&gt;, I tried building an AI app from scratch, primarily using vibe coding supported by &lt;a href=&#34;https://code.visualstudio.com/docs/copilot/overview&#34;&gt;GitHub Copilot in VSCode&lt;/a&gt;. Inspired by a recent Airbnb experience, I developed &lt;a href=&#34;https://github.com/tjards/ContactsnApp&#34;&gt;ContactsnApp&lt;/a&gt;: a user-friendly application designed to streamline the extraction and annotation of phone numbers from images using AI models.&lt;/p&gt;
&lt;h2 id=&#34;comments-from-the-co-author&#34;&gt;Comments from the Co-author&lt;/h2&gt;
&lt;p&gt;I asked ChatGPT how the project went. Here it is in her own words:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
